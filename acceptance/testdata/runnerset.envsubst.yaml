apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: ${NAME}
provisioner: rancher.io/local-path
reclaimPolicy: Retain
volumeBindingMode: WaitForFirstConsumer
---
apiVersion: actions.summerwind.dev/v1alpha1
kind: RunnerSet
metadata:
  name: ${NAME}
spec:
  # MANDATORY because it is based on StatefulSet: Results in a below error when omitted:
  #   missing required field "selector" in dev.summerwind.actions.v1alpha1.RunnerSet.spec
  selector:
    matchLabels:
      app: ${NAME}

  # MANDATORY because it is based on StatefulSet: Results in a below error when omitted:
  # missing required field "serviceName" in dev.summerwind.actions.v1alpha1.RunnerSet.spec]
  serviceName: ${NAME}

  #replicas: 1

  # From my limited testing, `ephemeral: true` is more reliable.
  # Seomtimes, updating already deployed runners from `ephemeral: false` to `ephemeral: true` seems to
  # result in queued jobs hanging forever.
  ephemeral: ${TEST_EPHEMERAL}

  enterprise: ${TEST_ENTERPRISE}
  group: ${TEST_GROUP}
  organization: ${TEST_ORG}
  repository: ${TEST_REPO}

  #
  # Custom runner image
  #
  image: ${RUNNER_NAME}:${RUNNER_TAG}

  #
  # dockerd within runner container
  #
  ## Replace `mumoshu/actions-runner-dind:dev` with your dind image
  #dockerdWithinRunnerContainer: true
  dockerdWithinRunnerContainer: ${RUNNER_DOCKERD_WITHIN_RUNNER_CONTAINER}

  #
  # Set the MTU used by dockerd-managed network interfaces (including docker-build-ubuntu)
  #
  #dockerMTU: 1450
  #Runner group
  # labels:
  # - "mylabel 1"
  # - "mylabel 2"
  labels:
  - "${RUNNER_LABEL}"
  #
  # Non-standard working directory
  #
  # workDir: "/"
  template:
    metadata:
      labels:
        app: ${NAME}
    spec:
      containers:
      - name: runner
        imagePullPolicy: IfNotPresent
      #- name: docker
      #  #image: mumoshu/actions-runner-dind:dev
  volumeClaimTemplates:
  - metadata:
      name: vol1
      labels:
        runnerset-volume-id: ${NAME}-vol1
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 10Mi
      storageClassName: ${NAME}
      ## Dunno which provider supports auto-provisioning with selector.
      ## At least the rancher local path provider stopped with:
      ##  waiting for a volume to be created, either by external provisioner "rancher.io/local-path" or manually created by system administrator
      # selector:
      #    matchLabels:
      #      runnerset-volume-id: ${NAME}-vol1
  - metadata:
      name: vol2
      labels:
        runnerset-volume-id: ${NAME}-vol2
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 10Mi
      storageClassName: ${NAME}
      # selector:
      #    matchLabels:
      #      runnerset-volume-id: ${NAME}-vol2
---
apiVersion: actions.summerwind.dev/v1alpha1
kind: HorizontalRunnerAutoscaler
metadata:
  name: ${NAME}
spec:
  scaleTargetRef:
    kind: RunnerSet
    name: ${NAME}
  scaleUpTriggers:
  - githubEvent:
      workflowJob: {}
    amount: 1
    duration: "10m"
  minReplicas: ${RUNNER_MIN_REPLICAS}
  maxReplicas: 10
  scaleDownDelaySecondsAfterScaleOut: ${RUNNER_SCALE_DOWN_DELAY_SECONDS_AFTER_SCALE_OUT}
